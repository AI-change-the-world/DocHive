import json
from sqlalchemy import select
from typing import Any, AsyncGenerator, Optional, BinaryIO
from models.database_models import (
    ClassTemplateConfigs,
    Document,
    ClassTemplate,
    DocumentType,
    DocumentTypeField,
)
from schemas.api_schemas import DocumentCreate, DocumentUpdate, SSEEvent
from utils.storage import storage_client
from utils.parser import DocumentParser
import uuid
import time
from pathlib import Path
from sqlalchemy.ext.asyncio import AsyncSession
from utils.llm_client import llm_client
from loguru import logger
from typing_extensions import deprecated

EXTRACT_FIELES_PROMPT = """
‰Ω†ÊòØ‰∏ÄÂêç‰ø°ÊÅØÊäΩÂèñ‰∏ìÂÆ∂„ÄÇËØ∑‰ªé‰ª•‰∏ãÊñáÊ°£‰∏≠ÊèêÂèñÊåáÂÆöÂ≠óÊÆµÁöÑ‰ø°ÊÅØÔºåÂπ∂‰ª• JSON Ê†ºÂºèËæìÂá∫„ÄÇ

„ÄêÂ≠óÊÆµÂÆö‰πâ„Äë
{{field_definitions}}

ÊØè‰∏™Â≠óÊÆµÂåÖÂê´‰ª•‰∏ã‰ø°ÊÅØÔºö
- field_nameÔºöÂ≠óÊÆµÂêçÔºà‰Ωú‰∏∫ JSON ÁöÑÈîÆÔºâ
- descriptionÔºöÂ≠óÊÆµÂê´‰πâÊàñÊèêÂèñËØ¥Êòé
- field_typeÔºöÂ≠óÊÆµÁ±ªÂûãÔºàÂèØ‰∏∫ text / date / arrayÔºâ

„ÄêËæìÂá∫Ë¶ÅÊ±Ç„Äë
1. ËæìÂá∫‰∏Ä‰∏™ÂÆåÊï¥ JSONÔºåÈîÆÂêç‰∏é field_name ÂØπÂ∫î„ÄÇ
2. Â¶ÇÊûúÊüê‰∏™Â≠óÊÆµÊó†Ê≥ïÁ°ÆÂÆöÂÜÖÂÆπÔºåËØ∑ËøîÂõû null„ÄÇ
3. ÂêÑÂ≠óÊÆµÂ§ÑÁêÜËßÑËåÉÔºö
   - textÔºöÊèêÂèñÊñá‰∏≠ÂØπÂ∫îÁöÑÊñáÂ≠óÂÜÖÂÆπ„ÄÇ
   - dateÔºöËØÜÂà´Âπ∂ËΩ¨Êç¢‰∏∫ YYYY-MM-DD Ê†ºÂºè„ÄÇ
   - arrayÔºöÊèêÂèñÂ§ö‰∏™Áõ∏ÂÖ≥È°πÔºå‰ª•Â≠óÁ¨¶‰∏≤Êï∞ÁªÑÂΩ¢ÂºèËøîÂõû„ÄÇ
4. ‰∏çË¶ÅÁîüÊàêÂ§ö‰ΩôËß£ÈáäÊàñËØ¥ÊòéÔºåÂè™ËæìÂá∫ JSON„ÄÇ

„ÄêÁ§∫‰æãËæìÂá∫„Äë
```json
{
  "Ê†áÈ¢ò": "ÂÖ≥‰∫éÊé®ËøõÊï∞Â≠óÊîøÂä°Âª∫ËÆæÁöÑËã•Âπ≤ÊÑèËßÅ",
  "ÂèëÊñáÂçï‰Ωç": "ÂõΩÂä°Èô¢ÂäûÂÖ¨ÂéÖ",
  "ÂèëÊñáÂ≠óÂè∑": "ÂõΩÂäûÂèë„Äî2023„Äï12Âè∑",
  "ÂèëÂ∏ÉÊó•Êúü": "2023-05-12"
}

„ÄêÂæÖÊèêÂèñÊñáÊ°£ÂÜÖÂÆπ„Äë
{{document_content}}
"""


CODE_EXTRACTION_PROMPT = """
‰Ω†ÊòØ‰∏Ä‰∏™ÊñáÊú¨ÂàÜÊûêÂä©ÁêÜÔºåÁî®‰∫é‰ªéÊñáÊ°£‰∏≠ÊèêÂèñ‰∏öÂä°ÁºñÁ†Å‰ø°ÊÅØ„ÄÇËØ∑‰ªîÁªÜÈòÖËØª‰ª•‰∏ã‰∏öÂä°ÁºñÁ†ÅÈÖçÁΩÆÔºö

JSON ÈÖçÁΩÆÔºö
{{JSON_CONFIG}}

ËØ¥ÊòéÔºö
1. level Ë°®Á§∫ÁºñÁ†ÅÂ±ÇÁ∫ßÔºå1 Ë°®Á§∫‰∏ÄÁ∫ßÁºñÁ†ÅÔºå2 Ë°®Á§∫‰∫åÁ∫ßÁºñÁ†Å„ÄÇ
2. name ÊòØÁºñÁ†ÅÂ≠óÊÆµÂêçÁß∞Ôºådescription ÊòØÂØπËØ•Â≠óÊÆµÁöÑÁÆÄÁü≠ÊèèËø∞„ÄÇ
3. code ÊòØÁºñÁ†ÅÊ†áËØÜ„ÄÇ
4. extraction_promptÔºàÂ¶ÇÊûúÊúâÔºâÊèê‰æõ‰∫ÜÂèØËÉΩÂÄºÊàñÂåπÈÖçÊèêÁ§∫„ÄÇ
5. Â¶ÇÊûú extraction_prompt ‰∏∫ nullÔºåËØ∑Ê†πÊçÆÊñáÊú¨ÂÜÖÂÆπÁõ¥Êé•ÊèêÂèñÂØπÂ∫îÂÄº„ÄÇ

ËØ∑‰Ω†ÁîüÊàê‰∏Ä‰∏™‰ºòÂåñÂêéÁöÑÊèêÂèñÁºñÁ†ÅÁöÑÊåá‰ª§Ê®°ÊùøÔºàpromptÔºâÔºåË¶ÅÊ±ÇÔºö
- ËÉΩÊòéÁ°ÆÂëäËØâÊ®°ÂûãË¶ÅÊèêÂèñÂì™‰∫õÂ≠óÊÆµ„ÄÇ
- ÂØπÊØè‰∏™Â≠óÊÆµÊèê‰æõÊèêÂèñËßÑÂàôÊàñÊèêÁ§∫„ÄÇ
- ËæìÂá∫Ê†ºÂºè‰∏∫ JSON ÂàóË°®ÔºåÁ§∫‰æãÔºö
[
  {"code":"YEAR", "value":"2025", "level":1},
  {"code":"REGION", "value":"JS", "level":2}
]
- ÈÅáÂà∞Êó†Ê≥ïÊèêÂèñÁöÑÂ≠óÊÆµÂèØ‰ª•ËøîÂõû null„ÄÇ
- ‰∏çË¶ÅÊ∑ªÂä†Â§ö‰ΩôËß£ÈáäÔºåÁõ¥Êé•ÁîüÊàêÂèØ‰ª•Áõ¥Êé•Áî®‰∫éË∞ÉÁî®Ê®°ÂûãÁöÑ prompt„ÄÇ

"""

TYPE_CLASSIFICATION_PROMPT = """
‰Ω†ÊòØ‰∏Ä‰∏™ÊîøÂ∫úÂÖ¨ÊñáÊô∫ËÉΩÂàÜÁ±ªÂä©ÊâãÔºåËØ∑Ê†πÊçÆÊñáÊ°£ÂÜÖÂÆπÂà§Êñ≠ÂÖ∂ÊâÄÂ±ûÁöÑÊñáÊ°£Á±ªÂûã„ÄÇ

‰ª•‰∏ãÊòØÊñáÊ°£Á±ªÂûãÂÆö‰πâË°®Ôºàtype_code„ÄÅtype_name„ÄÅdescriptionÔºâÔºö

{{type_code}}

ËØ∑ÈòÖËØª‰ª•‰∏ãÊñáÊ°£ÂÜÖÂÆπÔºåÂà§Êñ≠ËØ•ÊñáÊ°£ÊúÄÁ¨¶ÂêàÁöÑÁ±ªÂûãÔºåÂπ∂ËæìÂá∫ÁªìÊûú„ÄÇ

Ë¶ÅÊ±ÇÔºö
1. Âè™ËÉΩÈÄâÊã©‰∏Ä‰∏™ÊúÄÂêàÈÄÇÁöÑÁ±ªÂûã„ÄÇ
2. ËæìÂá∫Ê†ºÂºè‰∏∫ JSONÔºö
{
  "type_code": "XXX",
  "type_name": "XXX",
  "reason": "ÁÆÄË¶ÅËØ¥ÊòéÂà§Êñ≠‰æùÊçÆ"
}

Á§∫‰æãËæìÂÖ•Ôºö
„ÄäÂÖ≥‰∫éÂç∞Âèë„ÄàÂ∏ÇÁßëÊäÄÂàõÊñ∞ÂèëÂ±ïËßÑÂàíÔºà2025-2030Ôºâ„ÄâÁöÑÈÄöÁü•„Äã

Á§∫‰æãËæìÂá∫Ôºö
{
  "type_code": "GH",
  "type_name": "ËßÑÂàíÊñπÊ°à",
  "reason": "Êñá‰∏≠ÂåÖÂê´‚ÄúÂèëÂ±ïËßÑÂàí‚ÄùÔºåÂ±û‰∫éËÆ°ÂàíÁ±ªÊñá‰ª∂"
}

Áé∞Âú®ËØ∑Âà§Êñ≠‰ª•‰∏ãÊñáÊ°£ÁöÑÁ±ªÂûãÔºö

{{doc}}
"""


class DocumentService:
    """ÊñáÊ°£ÊúçÂä°Â±Ç"""

    @staticmethod
    async def upload_file_stream(
        db: AsyncSession,
        file_data: BinaryIO,
        filename: str,
        document_data: DocumentCreate,
        user_id: int,
    ) -> AsyncGenerator[str, Any]:
        """
        ‰∏ä‰º†Âπ∂Ëß£ÊûêÊñáÊ°£ÔºàÊµÅÂºèÂ§ÑÁêÜÔºâ
        """

        event = SSEEvent(event="process document content")

        file_extension = Path(filename).suffix
        object_name = f"{uuid.uuid4()}{file_extension}"

        # 1Ô∏è‚É£ ËØªÂèñÊñá‰ª∂ÂÜÖÂÆπÔºàÂè™ËØª‰∏ÄÊ¨°Ôºâ
        file_bytes = file_data.read()
        if hasattr(file_data, "seek"):
            file_data.seek(0)

        # 2Ô∏è‚É£ Ê®°Êãü‰∏ä‰º†ÔºàÊ≠§Â§ÑÁúÅÁï•ÂÆûÈôÖ‰∏ä‰º†Ôºâ
        file_path = f"{object_name}"
        event.data = "[info] ‰∏ä‰º†Êñá‰ª∂ÊàêÂäü"
        yield event.model_dump_json(ensure_ascii=False)

        # 3Ô∏è‚É£ Ëß£ÊûêÊñáÊú¨ÂÜÖÂÆπ
        # ‚ö†Ô∏è Ê≥®ÊÑèËøôÈáå‰∏çË¶ÅÂÜç .read()ÔºåÂõ†‰∏∫ÊµÅÂ∑≤ÁªèËØªËøáÔºåÁõ¥Êé•Áî® file_bytes
        doc = await DocumentParser.parse_file(file_bytes, file_extension)

        # 4Ô∏è‚É£ Ëé∑ÂèñÊ®°Êùø
        template_id = document_data.template_id
        result = await db.execute(
            select(ClassTemplate).where(ClassTemplate.id == template_id)
        )
        template = result.scalar_one_or_none()

        if not template:
            event.done = True
            event.data = "[error] Ê®°Êùø‰∏çÂ≠òÂú®"
            yield event.model_dump_json(ensure_ascii=False)
            return

        # 5Ô∏è‚É£ Ëé∑ÂèñÊñáÊ°£Á±ªÂûã
        doc_type_result = await db.execute(
            select(DocumentType).where(DocumentType.template_id == template_id)
        )
        doc_types = doc_type_result.scalars().all()

        if not doc_types:
            event.done = True
            event.data = "[error] ÊñáÊ°£Á±ªÂûã‰∏çÂ≠òÂú®"
            yield event.model_dump_json(ensure_ascii=False)
            return

        # 6Ô∏è‚É£ Ëé∑ÂèñÊ®°ÊùøÁöÑÂ±ÇÁ∫ßÂÆö‰πâ
        template_json_list: list = template.levels or []

        # 7Ô∏è‚É£ Ê£ÄÊü•Âπ∂ÁîüÊàêÁºñÁ†ÅÊèêÂèñÊèêÁ§∫
        class_template_config_result = await db.execute(
            select(ClassTemplateConfigs).where(
                ClassTemplateConfigs.template_id == template_id,
                ClassTemplateConfigs.config_name == "code_extraction_prompt",
            )
        )
        class_template_config = class_template_config_result.scalar_one_or_none()

        type_level = -1
        new_list = []
        for i in template_json_list:
            if i.get("is_doc_type", False):
                type_level = i.get("level", -1)
                continue
            new_list.append(i)

        if class_template_config:
            code_prompt = class_template_config.config_value
            event.data = "[info] ‰ΩøÁî®Ëá™ÂÆö‰πâÁöÑÁºñÁ†ÅÊèêÂèñÊèêÁ§∫"
            yield event.model_dump_json(ensure_ascii=False)
        else:
            event.data = "[info] ÈáçÊñ∞ÊûÑÈÄ†ÁºñÁ†ÅÊèêÂèñÊèêÁ§∫"
            yield event.model_dump_json(ensure_ascii=False)

            prompt = CODE_EXTRACTION_PROMPT.replace(
                "{{JSON_CONFIG}}", json.dumps(new_list, ensure_ascii=False)
            )
            code_prompt = llm_client.chat_completion(prompt)

            # ‰øùÂ≠òÈÖçÁΩÆ
            new_config = ClassTemplateConfigs(
                template_id=template_id,
                config_name="code_extraction_prompt",
                config_value=code_prompt,
            )
            db.add(new_config)
            await db.commit()

        # 8Ô∏è‚É£ ÊèêÂèñÁºñÁ†ÅÁªìÊûú
        code_json: list = llm_client.extract_json_response(
            code_prompt + "\n\n‰ª•‰∏ã‰∏∫ÊñáÊ°£ÂÜÖÂÆπÔºåËØ∑Â∏ÆÊàëÊèêÂèñÔºö" + doc
        )
        logger.info("üëìÔ∏è ÁºñÁ†ÅÁªìÊûúÔºö" + str(code_json))
        event.data = f"[info] ÊèêÂèñÁºñÁ†ÅÁªìÊûúÔºö {code_json}"
        yield event.model_dump_json(ensure_ascii=False)

        # 9Ô∏è‚É£ ÊèêÂèñÊñáÊ°£Á±ªÂûã
        type_list = [
            {"type_code": i.type_code, "type_name": i.type_name, "description": i.description}
            for i in doc_types
        ]

        type_prompt = TYPE_CLASSIFICATION_PROMPT.replace(
            "{{type_code}}", json.dumps(type_list, ensure_ascii=False)
        ).replace("{{doc}}", doc)
        type_json = llm_client.extract_json_response(type_prompt)
        logger.info("ü©± ÊñáÊ°£Á±ªÂûãÔºö" + str(type_json))
        event.data = f"[info] ÊñáÊ°£Á±ªÂûãÔºö {type_json}"
        yield event.model_dump_json(ensure_ascii=False)

        # 10Ô∏è‚É£ ÂêàÂπ∂ÁºñÁ†ÅÂíåÂàÜÁ±ªÁªìÊûú
        type_json_into_code_json = {
            "code": "TYPE",
            "value": type_json.get("type_code", "UNKNOWN"),
            "level": type_level,
        }

        code_json.append(type_json_into_code_json)
        sorted_code_json = sorted(code_json, key=lambda x: x.get("level", 0))

        logger.info("‚úÖ ÂêàÂπ∂ÁºñÁ†ÅÂíåÂàÜÁ±ªÁªìÊûúÔºö "+ json.dumps(sorted_code_json, ensure_ascii=False))

        # 11Ô∏è‚É£ Ëé∑ÂèñÂØπÂ∫î DocumentType
        doc_type_result = await db.execute(
            select(DocumentType).where(
                DocumentType.type_code == type_json.get("type_code", "UNKNOWN"),
                DocumentType.template_id == template_id,
            )
        )
        doc_type = doc_type_result.scalar_one_or_none()

        # 12Ô∏è‚É£ ÊûÑÈÄ†Êñá‰ª∂ÁºñÁ†Å TODO ÊúâÊó∂ÂÄôSectorÊó†Ê≥ïÊ≠£Á°ÆËØÜÂà´ÔºåÈúÄË¶ÅÂ§ÑÁêÜ
        file_code_id_prefix = "-".join(str(i.get("value")) if i.get("value") is not None else "UNKNOWN" for i in sorted_code_json)
        logger.info("‚úÖ ÁºñÁ†ÅÁªìÊûúÔºö"+ file_code_id_prefix)
        event.data = f"[info] ÁºñÁ†ÅÁªìÊûúÔºö {file_code_id_prefix}"
        yield event.model_dump_json(ensure_ascii=False)

        final_code_id = file_code_id_prefix + "-" + str(uuid.uuid4())

        # 13Ô∏è‚É£ Êü•ËØ¢Á±ªÂûãÂ≠óÊÆµÂÆö‰πâ
        doc_type_fields_result = await db.execute(
            select(DocumentTypeField).where(
                DocumentTypeField.doc_type_id == (doc_type.id if doc_type else None)
            )
        )
        doc_type_fields = doc_type_fields_result.scalars().all()

        _extracted_data = {}

        if not doc_type_fields:
            event.data = "[info] ÊñáÊ°£Á±ªÂûãÂ≠óÊÆµ‰∏çÂ≠òÂú®,‰∏çÊèêÂèñÂÜÖÂÆπ"
            yield event.model_dump_json(ensure_ascii=False)
        else:
            event.data = "[info] ÊñáÊ°£Á±ªÂûãÂ≠óÊÆµÂ≠òÂú®ÔºåÂºÄÂßãÊèêÂèñÂÜÖÂÆπ"
            yield event.model_dump_json(ensure_ascii=False)

            _fields = [i.to_dict() for i in doc_type_fields]
            field_definitions = "\n".join(
                f"{i+1}. {f['field_name']}Ôºà{f['field_type']}ÔºâÔºö{f['description']}"
                for i, f in enumerate(_fields)
            )
            prompt = EXTRACT_FIELES_PROMPT.replace(
                "{{field_definitions}}", field_definitions
            ).replace("{{document_content}}", doc)
            _extracted_data = llm_client.extract_json_response(prompt)

        # 14Ô∏è‚É£ ‰øùÂ≠òÊñáÊ°£‰ø°ÊÅØ
        document = Document(
            title=document_data.title,
            original_filename=filename,
            file_path=file_path,
            class_code=final_code_id,
            file_type=file_extension.lstrip("."),
            file_size=len(file_bytes),
            template_id=document_data.template_id,
            doc_metadata=document_data.metadata or {},
            status="completed",
            uploader_id=user_id,
            content_text=doc,
            doc_type_id=doc_type.id if doc_type else 0,
            processed_time=int(time.time()),
            extracted_data=_extracted_data,
        )

        db.add(document)
        await db.commit()

        event.data = "[info] ÊñáÊ°£ÂàõÂª∫ÊàêÂäü"
        event.done = True
        yield event.model_dump_json(ensure_ascii=False)


    @deprecated("‰ΩøÁî®upload_file_stream‰ª£Êõø")
    @staticmethod
    async def upload_document(
        db: AsyncSession,
        file_data: BinaryIO,
        filename: str,
        document_data: DocumentCreate,
        user_id: int,
    ) -> Document:
        """
        ‰∏ä‰º†Âπ∂Ëß£ÊûêÊñáÊ°£

        Args:
            db: Êï∞ÊçÆÂ∫ì‰ºöËØù
            file_data: Êñá‰ª∂Êï∞ÊçÆÊµÅ
            filename: ÂéüÂßãÊñá‰ª∂Âêç
            document_data: ÊñáÊ°£ÂàõÂª∫Êï∞ÊçÆ
            user_id: ‰∏ä‰º†Áî®Êà∑ID

        Returns:
            ÂàõÂª∫ÁöÑÊñáÊ°£ËÆ∞ÂΩï
        """
        # Ëé∑ÂèñÊñá‰ª∂Êâ©Â±ïÂêç
        file_extension = Path(filename).suffix

        # ÁîüÊàêÂîØ‰∏ÄÂØπË±°Âêç
        import datetime

        object_name = f"{datetime.datetime.utcnow().strftime('%Y/%m/%d')}/{uuid.uuid4()}{file_extension}"

        # ËØªÂèñÊñá‰ª∂Êï∞ÊçÆ
        file_bytes = file_data.read()
        file_data.seek(0)

        # ‰∏ä‰º†Âà∞ÂØπË±°Â≠òÂÇ®
        file_path = await storage_client.upload_file(
            file_data,
            object_name,
            content_type=DocumentService._get_content_type(file_extension),
        )

        # ÂàõÂª∫ÊñáÊ°£ËÆ∞ÂΩï
        document = Document(
            title=document_data.title,
            original_filename=filename,
            file_path=file_path,
            file_type=file_extension.lstrip("."),
            file_size=len(file_bytes),
            template_id=document_data.template_id,
            doc_metadata=document_data.metadata or {},
            status="pending",
            uploader_id=user_id,
        )

        db.add(document)
        await db.commit()
        await db.refresh(document)

        # ÂºÇÊ≠•Ëß£ÊûêÊñáÊ°£ÔºàÂÆûÈôÖÂ∫îËØ•‰ΩøÁî® Celery ‰ªªÂä°ÈòüÂàóÔºâ
        # REPLACE: ÊµÅÂºèÊé•Âè£Êõ¥Â•Ω
        try:
            await DocumentService.parse_document(
                db, document.id, file_bytes, file_extension
            )
        except Exception as e:
            document.status = "failed"
            document.error_message = str(e)
            await db.commit()

        return document

    @deprecated("Â∑≤ÂºÉÁî®")
    @staticmethod
    async def parse_document(
        db: AsyncSession,
        document_id: int,
        file_data: bytes,
        file_extension: str,
    ):
        """Ëß£ÊûêÊñáÊ°£ÂÜÖÂÆπ"""
        document = await DocumentService.get_document(db, document_id)
        if not document:
            return

        try:
            document.status = "processing"
            await db.commit()

            # Ëß£ÊûêÊñáÊú¨ÂÜÖÂÆπ
            content_text = await DocumentParser.parse_file(file_data, file_extension)

            # ÊèêÂèñÂÖÉ‰ø°ÊÅØ
            metadata = DocumentParser.extract_metadata(file_data, file_extension)

            # ÁîüÊàêÊëòË¶ÅÔºàËøôÈáåÁÆÄÂåñÂ§ÑÁêÜÔºåÂÆûÈôÖÂ∫îËØ•Ë∞ÉÁî® LLMÔºâ
            summary = content_text[:500] if len(content_text) > 500 else content_text

            # Êõ¥Êñ∞ÊñáÊ°£
            document.content_text = content_text
            document.summary = summary
            # ÂêàÂπ∂ doc_metadata
            current_metadata = document.doc_metadata or {}
            current_metadata.update(metadata)
            document.doc_metadata = current_metadata
            document.status = "completed"
            setattr(document, "processed_time", int(time.time()))

            await db.commit()

        except Exception as e:
            document.status = "failed"
            document.error_message = str(e)
            await db.commit()
            raise

    @staticmethod
    async def get_document(db: AsyncSession, document_id: int) -> Optional[Document]:
        """Ëé∑ÂèñÊñáÊ°£"""
        result = await db.execute(select(Document).where(Document.id == document_id))
        return result.scalar_one_or_none()

    @staticmethod
    async def list_documents(
        db: AsyncSession,
        skip: int = 0,
        limit: int = 20,
        template_id: Optional[int] = None,
        status: Optional[str] = None,
        user_id: Optional[int] = None,
    ) -> tuple[list[Document], int]:
        """Ëé∑ÂèñÊñáÊ°£ÂàóË°®"""
        query = select(Document)
        count_query = select(Document)

        if template_id:
            query = query.where(Document.template_id == template_id)
            count_query = count_query.where(Document.template_id == template_id)

        if status:
            query = query.where(Document.status == status)
            count_query = count_query.where(Document.status == status)

        if user_id:
            query = query.where(Document.uploader_id == user_id)
            count_query = count_query.where(Document.uploader_id == user_id)

        query = query.order_by(Document.upload_time.desc()).offset(skip).limit(limit)

        result = await db.execute(query)
        documents = result.scalars().all()

        count_result = await db.execute(count_query)
        total = len(count_result.scalars().all())

        return list(documents), total

    @staticmethod
    async def update_document(
        db: AsyncSession,
        document_id: int,
        document_data: DocumentUpdate,
    ) -> Optional[Document]:
        """Êõ¥Êñ∞ÊñáÊ°£"""
        document = await DocumentService.get_document(db, document_id)
        if not document:
            return None

        update_data = document_data.model_dump(exclude_unset=True)

        for field, value in update_data.items():
            setattr(document, field, value)

        await db.commit()
        await db.refresh(document)
        return document

    @staticmethod
    async def delete_document(db: AsyncSession, document_id: int) -> bool:
        """Âà†Èô§ÊñáÊ°£"""
        document = await DocumentService.get_document(db, document_id)
        if not document:
            return False

        # ‰ªéÂØπË±°Â≠òÂÇ®Âà†Èô§Êñá‰ª∂
        object_name = (
            document.file_path.split("/", 1)[1]
            if "/" in document.file_path
            else document.file_path
        )
        await storage_client.delete_file(object_name)

        # ‰ªéÊï∞ÊçÆÂ∫ìÂà†Èô§
        await db.delete(document)
        await db.commit()
        return True

    @staticmethod
    async def get_download_url(db: AsyncSession, document_id: int) -> Optional[str]:
        """Ëé∑ÂèñÊñáÊ°£‰∏ãËΩΩÈìæÊé•"""
        document = await DocumentService.get_document(db, document_id)
        if not document:
            return None

        # ÊèêÂèñÂØπË±°Âêç
        object_name = (
            document.file_path.split("/", 1)[1]
            if "/" in document.file_path
            else document.file_path
        )

        return storage_client.get_presigned_url(object_name)

    @staticmethod
    def _get_content_type(file_extension: str) -> str:
        """Ëé∑ÂèñÊñá‰ª∂ MIME Á±ªÂûã"""
        content_types = {
            ".pdf": "application/pdf",
            ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            ".doc": "application/msword",
            ".txt": "text/plain",
            ".md": "text/markdown",
            ".png": "image/png",
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
        }
        return content_types.get(file_extension.lower(), "application/octet-stream")
