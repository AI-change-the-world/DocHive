"""
Function Calling è·¯ç”±å™¨

è®© LLM è‡ªä¸»å†³ç­–æ˜¯å¦è°ƒç”¨å·¥å…·ä»¥åŠè°ƒç”¨å“ªä¸ªå·¥å…·
"""

import json
from typing import Any, Dict, List, Optional

from loguru import logger
from sqlalchemy.ext.asyncio import AsyncSession

from services.agent_tools import TOOLS_SCHEMA, execute_tool_call
from utils.llm_client import llm_client


# ==================== Function Calling è·¯ç”± ====================


async def function_calling_router(
    query: str, template_id: int, db: AsyncSession
) -> Dict[str, Any]:
    """
    Function Calling è·¯ç”±å™¨

    è®© LLM è‡ªä¸»å†³ç­–æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼Œä»¥åŠè°ƒç”¨å“ªä¸ªå·¥å…·ã€‚

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        template_id: æ¨¡æ¿ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        {
            "need_tool": bool,
            "tool_calls": [...],  # LLM è¿”å›çš„å·¥å…·è°ƒç”¨åˆ—è¡¨
            "tool_results": [...],  # å·¥å…·æ‰§è¡Œç»“æœåˆ—è¡¨
            "need_retrieval": bool,
        }
    """
    try:
        # 1. æ„é€ å·¥å…·æè¿°ï¼ˆç»™ LLM çœ‹çš„ï¼‰
        tools_description = json.dumps(TOOLS_SCHEMA, ensure_ascii=False, indent=2)

        # 2. æ„é€ ç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤Ÿé€šè¿‡è°ƒç”¨å·¥å…·æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·å½“å‰çš„æ¨¡æ¿ID: {template_id}

å¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼š
{tools_description}

è¯·åˆ¤æ–­ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼š

1. **éœ€è¦è°ƒç”¨å·¥å…·çš„æƒ…å†µ**ï¼š
   - ç»Ÿè®¡æŸ¥è¯¢ï¼ˆæ–‡æ¡£æ•°é‡ã€åˆ†ç±»åˆ†å¸ƒç­‰ï¼‰
   - ä¿¡æ¯æŸ¥è¯¢ï¼ˆæ¨¡æ¿åˆ—è¡¨ã€æ–‡æ¡£ç±»å‹åˆ—è¡¨ç­‰ï¼‰
   - åˆ†ç±»ç­›é€‰ï¼ˆæŒ‰åˆ†ç±»ç¼–ç æŸ¥æ‰¾æ–‡æ¡£ï¼‰

2. **ä¸éœ€è¦è°ƒç”¨å·¥å…·çš„æƒ…å†µ**ï¼š
   - éœ€è¦è¯­ä¹‰ç†è§£çš„æ–‡æ¡£å†…å®¹æŸ¥è¯¢
   - éœ€è¦åŸºäºæ–‡æ¡£å†…å®¹ç”Ÿæˆç­”æ¡ˆçš„é—®é¢˜

å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·ï¼Œè¯·è¿”å› JSON æ ¼å¼ï¼š
{{
    "need_tool": true,
    "tool_calls": [
        {{
            "name": "å·¥å…·åç§°",
            "arguments": {{"å‚æ•°å": "å‚æ•°å€¼"}}
        }}
    ]
}}

å¦‚æœä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œè¯·è¿”å›ï¼š
{{
    "need_tool": false
}}

æ³¨æ„ï¼š
- ä½ å¯ä»¥ä¸€æ¬¡è°ƒç”¨å¤šä¸ªå·¥å…·
- å¦‚æœå·¥å…·éœ€è¦ template_id ä½†ä½ æ²¡æœ‰æä¾›ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¡«å……ä¸º {template_id}
- åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹
"""

        # 3. è°ƒç”¨ LLM
        logger.info("ğŸ§  è°ƒç”¨ LLM è¿›è¡Œ Function Calling...")

        response = await llm_client.extract_json_response(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query},
            ],
            db=db,
        )

        logger.info(f"LLM å“åº”: {response}")

        # 4. æ£€æŸ¥ LLM æ˜¯å¦é€‰æ‹©è°ƒç”¨å·¥å…·
        if not response.get("need_tool", False):
            # ä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œèµ°æ–‡æ¡£æ£€ç´¢
            logger.info("âœ… LLM å†³å®šä¸è°ƒç”¨å·¥å…·ï¼Œèµ°æ–‡æ¡£æ£€ç´¢æµç¨‹")
            return {
                "need_tool": False,
                "tool_calls": [],
                "tool_results": [],
                "need_retrieval": True,
            }

        # 5. æ‰§è¡Œå·¥å…·è°ƒç”¨
        tool_calls = response.get("tool_calls", [])
        logger.info(f"ğŸ”§ LLM è¦æ±‚è°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·")

        tool_results = []
        for tool_call in tool_calls:
            tool_name = tool_call.get("name")
            arguments = tool_call.get("arguments", {})

            # è‡ªåŠ¨å¡«å…… template_idï¼ˆå¦‚æœå·¥å…·éœ€è¦ä¸” LLM æœªæä¾›ï¼‰
            if "template_id" not in arguments and tool_name != "list_all_templates":
                arguments["template_id"] = template_id

            # æ‰§è¡Œå·¥å…·
            result = await execute_tool_call(tool_name, arguments, db)
            tool_results.append(
                {
                    "tool_name": tool_name,
                    "arguments": arguments,
                    "result": result,
                }
            )

        return {
            "need_tool": True,
            "tool_calls": tool_calls,
            "tool_results": tool_results,
            "need_retrieval": False,
        }

    except Exception as e:
        logger.error(f"âŒ Function Calling è·¯ç”±å¤±è´¥: {str(e)}")
        # é”™è¯¯æ—¶é»˜è®¤èµ°æ–‡æ¡£æ£€ç´¢
        return {
            "need_tool": False,
            "tool_calls": [],
            "tool_results": [],
            "need_retrieval": True,
        }


async def format_tool_result_as_answer(
    tool_result: Dict[str, Any], query: str, db: AsyncSession
) -> str:
    """
    å°†å·¥å…·è°ƒç”¨ç»“æœæ ¼å¼åŒ–ä¸ºè‡ªç„¶è¯­è¨€å›ç­”

    Args:
        tool_result: å·¥å…·æ‰§è¡Œç»“æœ
        query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        æ ¼å¼åŒ–åçš„è‡ªç„¶è¯­è¨€ç­”æ¡ˆ
    """
    try:
        # ä½¿ç”¨LLMå°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€
        prompt = f"""è¯·å°†ä»¥ä¸‹å·¥å…·æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºè‡ªç„¶ã€å‹å¥½çš„å›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {query}

æŸ¥è¯¢ç»“æœ:
{json.dumps(tool_result, ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. ç”¨è‡ªç„¶è¯­è¨€æè¿°ç»“æœ
2. çªå‡ºå…³é”®æ•°æ®å’Œé‡ç‚¹ä¿¡æ¯
3. å¦‚æœæœ‰åˆ—è¡¨æ•°æ®ï¼Œé€‚å½“å½’çº³æ€»ç»“
4. è¯­æ°”å‹å¥½ã€ä¸“ä¸š

è¯·ç›´æ¥è¿”å›å›ç­”å†…å®¹ï¼Œä¸è¦åŠ é¢å¤–è¯´æ˜ã€‚"""

        answer = await llm_client.chat_completion(prompt, db=db)
        return answer

    except Exception as e:
        logger.error(f"æ ¼å¼åŒ–å·¥å…·ç»“æœå¤±è´¥: {str(e)}")
        # é™çº§å¤„ç†ï¼šç›´æ¥è¿”å›JSON
        return f"æŸ¥è¯¢ç»“æœï¼š\n{json.dumps(tool_result, ensure_ascii=False, indent=2)}"
