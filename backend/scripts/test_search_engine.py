"""
æœç´¢å¼•æ“ŽåŠŸèƒ½æµ‹è¯•
æµ‹è¯•ä¸åŒæœç´¢å¼•æ“Žçš„åŸºæœ¬åŠŸèƒ½
"""

import asyncio
from utils.search_engine import (
    get_search_engine,
    DatabaseEngine,
    ElasticsearchEngine,
    ClickHouseEngine,
)
from config import get_settings
from datetime import datetime

settings = get_settings()


async def test_search_engine():
    """æµ‹è¯•æœç´¢å¼•æ“ŽåŸºæœ¬åŠŸèƒ½"""
    print("=" * 60)
    print("DocHive æœç´¢å¼•æ“Žæµ‹è¯•")
    print("=" * 60)
    print()

    # èŽ·å–æœç´¢å¼•æ“Žå®žä¾‹
    engine = get_search_engine()
    engine_type = type(engine).__name__

    print(f"ðŸ” å½“å‰æœç´¢å¼•æ“Ž: {engine_type}")
    print(f"ðŸ“ é…ç½®: SEARCH_ENGINE={settings.SEARCH_ENGINE}")
    print()

    try:
        # 1. æµ‹è¯•ç´¢å¼•åˆ›å»º
        print("ðŸ“¦ æµ‹è¯• 1: åˆ›å»º/ç¡®ä¿ç´¢å¼•...")
        await engine.ensure_index()
        print("âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ!")
        print()

        # 2. æµ‹è¯•æ–‡æ¡£ç´¢å¼•
        print("ðŸ“ æµ‹è¯• 2: ç´¢å¼•æµ‹è¯•æ–‡æ¡£...")
        test_doc = {
            "document_id": 9999,
            "title": "æµ‹è¯•æ–‡æ¡£ - æœç´¢å¼•æ“ŽåŠŸèƒ½éªŒè¯",
            "content": "è¿™æ˜¯ä¸€ä¸ªç”¨äºŽæµ‹è¯•æœç´¢å¼•æ“ŽåŠŸèƒ½çš„æ–‡æ¡£ã€‚åŒ…å«å…³é”®è¯ï¼šæµ‹è¯•ã€æœç´¢ã€å¼•æ“Žã€‚",
            "summary": "æœç´¢å¼•æ“ŽåŠŸèƒ½æµ‹è¯•æ–‡æ¡£",
            "class_path": {"level1": "æµ‹è¯•", "level2": "åŠŸèƒ½éªŒè¯"},
            "class_code": "TEST-001",
            "template_id": 1,
            "file_type": "txt",
            "upload_time": datetime.now(),
            "uploader_id": 1,
        }

        result = await engine.index_document(test_doc)
        if result:
            print("âœ… æ–‡æ¡£ç´¢å¼•æˆåŠŸ!")
        else:
            print("âš ï¸ æ–‡æ¡£ç´¢å¼•å¤±è´¥ (å¯èƒ½æ˜¯æ•°æ®åº“å¼•æ“Ž,ä¼šè‡ªåŠ¨ç´¢å¼•)")
        print()

        # 3. æµ‹è¯•æœç´¢åŠŸèƒ½
        print("ðŸ”Ž æµ‹è¯• 3: æœç´¢æµ‹è¯•...")

        # æµ‹è¯•å…³é”®è¯æœç´¢
        print("- æœç´¢å…³é”®è¯: 'æµ‹è¯•'")
        search_result = await engine.search_documents(
            keyword="æµ‹è¯•", page=1, page_size=10
        )
        print(f"  æ‰¾åˆ° {search_result['total']} ä¸ªç»“æžœ")
        if search_result["results"]:
            print(f"  ç¬¬ä¸€ä¸ªç»“æžœ: {search_result['results'][0]['title']}")
        print()

        # æµ‹è¯•æ— å…³é”®è¯æœç´¢ (åˆ—è¡¨æ‰€æœ‰)
        print("- æœç´¢æ‰€æœ‰æ–‡æ¡£")
        all_docs = await engine.search_documents(page=1, page_size=5)
        print(f"  æ€»å…± {all_docs['total']} ä¸ªæ–‡æ¡£")
        print()

        # 4. æµ‹è¯•åˆ é™¤
        print("ðŸ—‘ï¸  æµ‹è¯• 4: åˆ é™¤æµ‹è¯•æ–‡æ¡£...")
        delete_result = await engine.delete_document(9999)
        if delete_result:
            print("âœ… æ–‡æ¡£åˆ é™¤æˆåŠŸ!")
        else:
            print("âš ï¸ æ–‡æ¡£åˆ é™¤å¤±è´¥ (å¯èƒ½æ˜¯æ•°æ®åº“å¼•æ“Ž,ä¼šè‡ªåŠ¨åˆ é™¤)")
        print()

        print("=" * 60)
        print("âœ¨ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 60)

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()

    finally:
        # å…³é—­è¿žæŽ¥
        await engine.close()


async def test_all_engines():
    """æµ‹è¯•æ‰€æœ‰æœç´¢å¼•æ“Žç±»åž‹"""
    print("=" * 60)
    print("æµ‹è¯•æ‰€æœ‰æœç´¢å¼•æ“Žå®žçŽ°")
    print("=" * 60)
    print()

    engines = [
        ("Database", DatabaseEngine),
    ]

    # å¦‚æžœé…ç½®äº† ES,æ·»åŠ  ES æµ‹è¯•
    if settings.ELASTICSEARCH_URL:
        try:
            engines.append(("Elasticsearch", ElasticsearchEngine))
        except ImportError:
            print("âš ï¸ Elasticsearch åº“æœªå®‰è£…,è·³è¿‡æµ‹è¯•")

    # å¦‚æžœé…ç½®äº† ClickHouse,æ·»åŠ  ClickHouse æµ‹è¯•
    if settings.CLICKHOUSE_HOST:
        try:
            engines.append(("ClickHouse", ClickHouseEngine))
        except ImportError:
            print("âš ï¸ ClickHouse åº“æœªå®‰è£…,è·³è¿‡æµ‹è¯•")

    for engine_name, engine_class in engines:
        print(f"\n{'=' * 60}")
        print(f"æµ‹è¯• {engine_name} å¼•æ“Ž")
        print(f"{'=' * 60}\n")

        try:
            engine = engine_class()

            # æµ‹è¯•ç´¢å¼•åˆ›å»º
            await engine.ensure_index()
            print(f"âœ… {engine_name} ç´¢å¼•åˆ›å»ºæˆåŠŸ")

            # æµ‹è¯•æœç´¢
            results = await engine.search_documents(page=1, page_size=1)
            print(f"âœ… {engine_name} æœç´¢åŠŸèƒ½æ­£å¸¸ (å…± {results['total']} ä¸ªæ–‡æ¡£)")

            await engine.close()

        except Exception as e:
            print(f"âŒ {engine_name} æµ‹è¯•å¤±è´¥: {e}")


async def benchmark_search():
    """ç®€å•çš„æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("=" * 60)
    print("æœç´¢å¼•æ“Žæ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    print()

    engine = get_search_engine()
    engine_type = type(engine).__name__

    print(f"ðŸ” æµ‹è¯•å¼•æ“Ž: {engine_type}")
    print()

    # æµ‹è¯•ä¸åŒæŸ¥è¯¢çš„æ€§èƒ½
    test_cases = [
        ("ç©ºæŸ¥è¯¢ (åˆ—è¡¨æ‰€æœ‰)", {}),
        ("å…³é”®è¯æœç´¢", {"keyword": "æµ‹è¯•"}),
        ("åˆ†é¡µæŸ¥è¯¢", {"page": 1, "page_size": 20}),
    ]

    for test_name, params in test_cases:
        import time

        start = time.time()

        result = await engine.search_documents(**params)

        elapsed = (time.time() - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

        print(f"ðŸ“Š {test_name}")
        print(f"   è€—æ—¶: {elapsed:.2f}ms")
        print(f"   ç»“æžœ: {result['total']} ä¸ªæ–‡æ¡£")
        print()

    await engine.close()


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "all":
        # æµ‹è¯•æ‰€æœ‰å¼•æ“Ž
        asyncio.run(test_all_engines())
    elif len(sys.argv) > 1 and sys.argv[1] == "benchmark":
        # æ€§èƒ½æµ‹è¯•
        asyncio.run(benchmark_search())
    else:
        # åŸºæœ¬æµ‹è¯•
        asyncio.run(test_search_engine())
