import asyncio
import json
import traceback
import uuid
from typing import Any, Dict, Optional

from elasticsearch import AsyncElasticsearch
from fastapi import APIRouter, Depends, HTTPException, Request, status
from loguru import logger
from sqlalchemy.ext.asyncio import AsyncSession
from sse_starlette import EventSourceResponse

from api.deps import get_config, get_current_user, get_llm, get_search_engine
from config import DynamicConfig
from database import get_db
from models.database_models import User
from schemas.api_schemas import QARequest, QAResponse, ResponseBase, SSEEvent
from services.qa_service import QAService

# å¯¼å…¥search_agentç›¸å…³æ¨¡å—
from services.search_agent import RetrievalState
from services.search_agent import app as search_agent_app
from services.search_agent import graph_state_storage
from utils.llm_client import LLMClient
from utils.search_engine import SearchEngine

router = APIRouter(prefix="/qa", tags=["æ™ºèƒ½é—®ç­”"])


@router.post("/ask/stream")
async def ask_question_stream(
    qa_request: QARequest,
    db: AsyncSession = Depends(get_db),
    llm: LLMClient = Depends(get_llm),
    search_engine: SearchEngine = Depends(get_search_engine),
    current_user: User = Depends(get_current_user),
):
    """
    æµå¼é—®ç­”æ¥å£ï¼ˆSSEï¼‰

    - **question**: ç”¨æˆ·é—®é¢˜
    - **template_id**: é™å®šæ¨¡æ¿IDèŒƒå›´ï¼ˆå¯é€‰ï¼‰
    - **top_k**: æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤5ï¼ŒèŒƒå›´1-20ï¼‰

    è¿”å›æµå¼äº‹ä»¶ï¼š
    - **thinking**: æ€è€ƒè¿‡ç¨‹çŠ¶æ€æ›´æ–°
    - **references**: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å¼•ç”¨
    - **answer**: æµå¼ç”Ÿæˆçš„ç­”æ¡ˆç‰‡æ®µ
    - **complete**: å›ç­”å®Œæˆæ ‡è®°
    - **error**: é”™è¯¯ä¿¡æ¯
    """

    async def event_generator():
        """SSEäº‹ä»¶ç”Ÿæˆå™¨"""
        try:
            async for event in QAService.answer_question_stream(
                db,
                llm,
                search_engine,
                question=qa_request.question,
                template_id=qa_request.template_id,
                top_k=qa_request.top_k,
            ):
                # å°†äº‹ä»¶è½¬æ¢ä¸ºSSEæ ¼å¼
                yield {
                    "event": event.get("event", "message"),
                    "data": json.dumps(event, ensure_ascii=False),
                }

        except Exception as e:
            # å‘é€é”™è¯¯äº‹ä»¶
            yield {
                "data": json.dumps(
                    {
                        "event": "error",
                        "data": {"message": f"é—®ç­”å¤±è´¥: {str(e)}"},
                        "done": True,
                    },
                    ensure_ascii=False,
                ),
            }

    return EventSourceResponse(event_generator())


@router.post("/ask", response_model=ResponseBase)
async def ask_question(
    qa_request: QARequest,
    db: AsyncSession = Depends(get_db),
    llm: LLMClient = Depends(get_llm),
    search_engine: SearchEngine = Depends(get_search_engine),
    current_user: User = Depends(get_current_user),
):
    """
    éæµå¼é—®ç­”æ¥å£

    - **question**: ç”¨æˆ·é—®é¢˜
    - **template_id**: é™å®šæ¨¡æ¿IDèŒƒå›´ï¼ˆå¯é€‰ï¼‰
    - **top_k**: æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤5ï¼ŒèŒƒå›´1-20ï¼‰

    è¿”å›å®Œæ•´çš„é—®ç­”ç»“æœï¼ŒåŒ…æ‹¬ç­”æ¡ˆå’Œç›¸å…³æ–‡æ¡£å¼•ç”¨
    """
    try:
        result = await QAService.answer_question(
            db,
            llm,
            search_engine,
            question=qa_request.question,
            template_id=qa_request.template_id,
            top_k=qa_request.top_k,
        )

        return ResponseBase(
            message="é—®ç­”æˆåŠŸ",
            data=result,
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"é—®ç­”å¤±è´¥: {str(e)}",
        )


@router.post("/ask/agent/stream")
async def ask_question_agent_stream(
    request: Request,
    qa_request: QARequest,
    db: AsyncSession = Depends(get_db),
    config: DynamicConfig = Depends(get_config),
    current_user: User = Depends(get_current_user),
):
    """
    åŸºäºLangGraphæ™ºèƒ½ä½“çš„æµå¼é—®ç­”æ¥å£ï¼ˆSSEï¼‰

    - **question**: ç”¨æˆ·é—®é¢˜
    - **template_id**: é™å®šæ¨¡æ¿IDèŒƒå›´ï¼ˆå¿…éœ€ï¼‰
    - **top_k**: æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤5ï¼ŒèŒƒå›´1-20ï¼‰

    è¿”å›æµå¼äº‹ä»¶ï¼š
    - **thinking**: æ€è€ƒè¿‡ç¨‹çŠ¶æ€æ›´æ–°
    - **references**: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å¼•ç”¨
    - **answer**: æµå¼ç”Ÿæˆçš„ç­”æ¡ˆç‰‡æ®µ
    - **complete**: å›ç­”å®Œæˆæ ‡è®°
    - **error**: é”™è¯¯ä¿¡æ¯
    - **ambiguity**: éœ€è¦ç”¨æˆ·æ¾„æ¸…çš„é—®é¢˜
    """

    # æ£€æŸ¥template_idæ˜¯å¦æä¾›
    if not qa_request.template_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ä½¿ç”¨æ™ºèƒ½ä½“é—®ç­”å¿…é¡»æä¾›template_id",
        )

    async def event_generator():
        """SSEäº‹ä»¶ç”Ÿæˆå™¨"""
        es_client = None  # åˆå§‹åŒ–
        # ç”Ÿæˆä¼šè¯/ä»»åŠ¡IDï¼ˆæ•´ä¸ªæµç¨‹ä½¿ç”¨åŒä¸€ä¸ªUUIDï¼‰
        task_id = str(uuid.uuid4())
        try:
            # ç”Ÿæˆä¼šè¯ID
            session_id = str(uuid.uuid4())

            # åˆå§‹åŒ–Elasticsearchå®¢æˆ·ç«¯
            es_client = AsyncElasticsearch(
                [config.ELASTICSEARCH_URL], verify_certs=False
            )
            # æ„é€ åˆå§‹çŠ¶æ€ (ä¼˜åŒ–åçš„çŠ¶æ€æœº)
            initial_state: RetrievalState = {
                # å¿…éœ€è¾“å…¥
                "query": qa_request.question,
                "template_id": qa_request.template_id or 0,
                "session_id": session_id,
                # èŠ‚ç‚¹ 0 (ä»»åŠ¡è§„åˆ’) äº§å‡º
                "execution_plan": [],
                "reasoning": "",
                "tool_results": [],
                "need_retrieval": True,
                # èŠ‚ç‚¹ 1 (ESå…¨æ–‡æ£€ç´¢) äº§å‡º
                "es_fulltext_results": [],
                "es_document_ids": set(),
                # èŠ‚ç‚¹ 2 (SQLç»“æ„åŒ–æ£€ç´¢) äº§å‡º
                "class_template_levels": None,
                "category": "*",
                "category_field_code": None,
                "sql_extracted_conditions": [],
                "sql_document_ids": set(),
                # èŠ‚ç‚¹ 3 (ç»“æœèåˆ) äº§å‡º
                "merged_document_ids": [],
                "merged_documents": [],
                "fusion_strategy": "none",
                # èŠ‚ç‚¹ 4 (ç²¾ç»†åŒ–ç­›é€‰) äº§å‡º
                "document_type_fields": [],
                "refined_conditions": {},
                "final_es_query": None,
                "final_results": [],
                # èŠ‚ç‚¹ 5 (æ­§ä¹‰å¤„ç†) äº§å‡º
                "ambiguity_message": None,
                # èŠ‚ç‚¹ 6 (ç”Ÿæˆç­”æ¡ˆ) äº§å‡º
                "answer": None,
            }

            logger.info(f"[LangGraph initial_state] {initial_state}")

            # å‘é€å¼€å§‹å¤„ç†æ¶ˆæ¯
            yield SSEEvent(
                event="thinking",
                data={
                    "stage": "start",
                    "message": "å¼€å§‹å¤„ç†æ‚¨çš„é—®é¢˜...",
                },
                id=task_id,
                done=False,
            ).model_dump_json()

            # å…ˆæ‰§è¡Œæ„å›¾è¯†åˆ«ï¼Œè·å–æ‰§è¡Œè®¡åˆ’
            first_step = True
            execution_plan = []

            # ä½¿ç”¨astreamæ–¹å¼å¼‚æ­¥æµå¼å¤„ç†LangGraphï¼ˆä¿®å¤ï¼šå¼‚æ­¥èŠ‚ç‚¹å¿…é¡»ç”¨å¼‚æ­¥streamï¼‰
            state_data = None  # åˆå§‹åŒ–ï¼Œç”¨äºä¿å­˜æœ€ç»ˆçŠ¶æ€
            async for step_result in search_agent_app.astream(
                initial_state,
                config={
                    "configurable": {
                        "db": db,
                        "es": es_client,
                        "es_index": config.ELASTICSEARCH_INDEX,
                    }
                },
            ):
                logger.info(f"[LangGraph step_result.keys()] {step_result.keys()}")
                # è·å–èŠ‚ç‚¹åç§°å’ŒçŠ¶æ€æ•°æ®
                node_name = list(step_result.keys())[0]
                state_data = step_result[node_name]

                print(f"[LangGraph Node] {node_name}")

                # ç¬¬ä¸€ä¸ªèŠ‚ç‚¹æ˜¯ intent_routingï¼Œæ ¹æ®æ‰§è¡Œè®¡åˆ’ç”Ÿæˆå‰ç«¯æ¸²æŸ“æ­¥éª¤
                if first_step and node_name == "intent_routing":
                    first_step = False

                    # è·å– LLM è§„åˆ’çš„æ‰§è¡Œè®¡åˆ’
                    llm_execution_plan = state_data.get("execution_plan", [])
                    reasoning = state_data.get("reasoning", "")

                    logger.info(f"ğŸ“‹ LLMæ‰§è¡Œè®¡åˆ’: {llm_execution_plan}")
                    logger.info(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {reasoning}")

                    # æ ¹æ®æ‰§è¡Œè®¡åˆ’åŠ¨æ€ç”Ÿæˆå‰ç«¯æ¸²æŸ“æ­¥éª¤
                    frontend_plan = []

                    # æ€»æ˜¯å…ˆæ·»åŠ ä»»åŠ¡è§„åˆ’æ­¥éª¤
                    frontend_plan.append(
                        {"stage": "intent_routing", "name": "ä»»åŠ¡è§„åˆ’", "icon": "ğŸ§ "}
                    )

                    # éå† LLM çš„æ‰§è¡Œè®¡åˆ’ï¼Œè½¬æ¢ä¸ºå‰ç«¯æ­¥éª¤
                    for step in llm_execution_plan:
                        action = step.get("action")
                        description = step.get("description", "")

                        if action == "tool_call":
                            # å·¥å…·è°ƒç”¨æ­¥éª¤ï¼ˆåˆå¹¶æ‰€æœ‰å·¥å…·è°ƒç”¨ä¸ºä¸€ä¸ªæ­¥éª¤ï¼‰
                            if not any(
                                s["stage"] == "tool_answer" for s in frontend_plan
                            ):
                                frontend_plan.append(
                                    {
                                        "stage": "tool_answer",
                                        "name": "å·¥å…·æ‰§è¡Œ",
                                        "icon": "ğŸ”§",
                                    }
                                )
                        elif action == "document_retrieval":
                            # æ–‡æ¡£æ£€ç´¢æ­¥éª¤ï¼ˆåŒ…å«å®Œæ•´çš„æ£€ç´¢æµç¨‹ï¼‰
                            frontend_plan.extend(
                                [
                                    {
                                        "stage": "es_fulltext",
                                        "name": "ESå…¨æ–‡æ£€ç´¢",
                                        "icon": "ğŸ”",
                                    },
                                    {
                                        "stage": "sql_structured",
                                        "name": "SQLç»“æ„åŒ–æ£€ç´¢",
                                        "icon": "ğŸ“Š",
                                    },
                                    {
                                        "stage": "merge_results",
                                        "name": "ç»“æœèåˆ",
                                        "icon": "ğŸ”€",
                                    },
                                    {
                                        "stage": "refined_filter",
                                        "name": "ç²¾ç»†åŒ–ç­›é€‰",
                                        "icon": "âœ¨",
                                    },
                                ]
                            )

                    # æ€»æ˜¯æœ€åæ·»åŠ ç­”æ¡ˆç”Ÿæˆæ­¥éª¤
                    frontend_plan.append(
                        {"stage": "generate_answer", "name": "ç”Ÿæˆç­”æ¡ˆ", "icon": "ğŸ“"}
                    )

                    # åˆ¤æ–­æ¨¡å¼
                    has_tool = any(
                        step.get("action") == "tool_call" for step in llm_execution_plan
                    )
                    has_retrieval = any(
                        step.get("action") == "document_retrieval"
                        for step in llm_execution_plan
                    )

                    if has_tool and has_retrieval:
                        mode = "combined_query"
                    elif has_tool:
                        mode = "tool_calling"
                    else:
                        mode = "document_retrieval"

                    logger.info(f"ğŸ¯ å‰ç«¯æ¸²æŸ“è®¡åˆ’: {len(frontend_plan)} ä¸ªæ­¥éª¤")
                    logger.info(f"ğŸ“Œ æ‰§è¡Œæ¨¡å¼: {mode}")

                    # å‘é€æ‰§è¡Œè®¡åˆ’äº‹ä»¶
                    yield SSEEvent(
                        event="execution_plan",
                        data={
                            "plan": frontend_plan,
                            "mode": mode,
                            "reasoning": reasoning,  # ä¼ é€’ LLM çš„æ¨ç†è¿‡ç¨‹
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                # æ ¹æ®èŠ‚ç‚¹å‘é€ç›¸åº”äº‹ä»¶
                if node_name == "intent_routing":
                    # ä»»åŠ¡è§„åˆ’èŠ‚ç‚¹
                    execution_plan = state_data.get("execution_plan", [])
                    reasoning = state_data.get("reasoning", "")
                    tool_count = len(
                        [s for s in execution_plan if s.get("action") == "tool_call"]
                    )
                    has_retrieval = any(
                        s.get("action") == "document_retrieval" for s in execution_plan
                    )

                    yield SSEEvent(
                        event="stage_complete",
                        data={
                            "stage": "intent_routing",
                            "message": f"ä»»åŠ¡è§„åˆ’å®Œæˆ: {tool_count}ä¸ªå·¥å…·è°ƒç”¨ + {'æ–‡æ¡£æ£€ç´¢' if has_retrieval else 'æ— éœ€æ£€ç´¢'}",
                            "result": {
                                "execution_plan": execution_plan,
                                "reasoning": reasoning,
                                "tool_count": tool_count,
                                "has_retrieval": has_retrieval,
                            },
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                elif node_name == "tool_answer":
                    # å·¥å…·è°ƒç”¨ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹
                    tool_results = state_data.get("tool_results", [])
                    yield SSEEvent(
                        event="stage_complete",
                        data={
                            "stage": "tool_answer",
                            "message": "å·¥å…·è°ƒç”¨å®Œæˆ",
                            "result": {
                                "tools_count": len(tool_results),
                                "results": tool_results,
                            },
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                elif node_name == "es_fulltext":
                    # å…ˆå‘é€stage_startäº‹ä»¶
                    yield SSEEvent(
                        event="stage_start",
                        data={
                            "stage": "es_fulltext",
                            "message": "æ­£åœ¨è¿›è¡ŒESå…¨æ–‡æ£€ç´¢...",
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                    # å†å‘é€stage_completeäº‹ä»¶
                    es_doc_ids = list(state_data.get("es_document_ids", set()))
                    es_results = state_data.get("es_fulltext_results", [])[:10]
                    doc_summaries = [
                        {
                            "document_id": doc.get("document_id"),
                            "title": doc.get("title", ""),
                            "snippet": (
                                doc.get("content", "")[:100] + "..."
                                if doc.get("content")
                                else ""
                            ),
                        }
                        for doc in es_results
                    ]
                    yield SSEEvent(
                        event="stage_complete",
                        data={
                            "stage": "es_fulltext",
                            "message": f"ESæ£€ç´¢å®Œæˆï¼Œå¬å› {len(es_doc_ids)} ç¯‡æ–‡æ¡£",
                            "result": {
                                "document_ids": es_doc_ids,
                                "count": len(es_doc_ids),
                                "documents": doc_summaries,
                            },
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                elif node_name == "sql_structured":
                    # å…ˆå‘é€stage_startäº‹ä»¶
                    yield SSEEvent(
                        event="stage_start",
                        data={
                            "stage": "sql_structured",
                            "message": "æ­£åœ¨è¿›è¡ŒSQLç»“æ„åŒ–æ£€ç´¢...",
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                    # å†å‘é€stage_completeäº‹ä»¶
                    sql_doc_ids = list(state_data.get("sql_document_ids", set()))
                    yield SSEEvent(
                        event="stage_complete",
                        data={
                            "stage": "sql_structured",
                            "message": f"SQLæ£€ç´¢å®Œæˆï¼Œå¬å› {len(sql_doc_ids)} ç¯‡æ–‡æ¡£",
                            "result": {
                                "document_ids": sql_doc_ids,
                                "count": len(sql_doc_ids),
                                "category": state_data.get("category", "*"),
                                "conditions": state_data.get(
                                    "sql_extracted_conditions", []
                                ),
                            },
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                elif node_name == "merge_results":
                    # å…ˆå‘é€stage_startäº‹ä»¶
                    yield SSEEvent(
                        event="stage_start",
                        data={
                            "stage": "merge_results",
                            "message": "æ­£åœ¨èåˆæ£€ç´¢ç»“æœ...",
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                    # å†å‘é€stage_completeäº‹ä»¶
                    merged_ids = state_data.get("merged_document_ids", [])
                    yield SSEEvent(
                        event="stage_complete",
                        data={
                            "stage": "merge_results",
                            "message": f"ç»“æœèåˆå®Œæˆï¼Œèåˆå {len(merged_ids)} ç¯‡æ–‡æ¡£",
                            "result": {
                                "document_ids": merged_ids,
                                "count": len(merged_ids),
                                "strategy": state_data.get("fusion_strategy", "none"),
                            },
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                elif node_name == "refined_filter":
                    # å…ˆå‘é€stage_startäº‹ä»¶
                    yield SSEEvent(
                        event="stage_start",
                        data={
                            "stage": "refined_filter",
                            "message": "æ­£åœ¨è¿›è¡Œç²¾ç»†åŒ–ç­›é€‰...",
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                    # å†å‘é€stage_completeäº‹ä»¶
                    final_results = state_data.get("final_results", [])
                    result_summaries = [
                        {
                            "document_id": doc.get("document_id"),
                            "title": doc.get("title", ""),
                            "snippet": (
                                doc.get("content", "")[:100] + "..."
                                if doc.get("content")
                                else ""
                            ),
                        }
                        for doc in final_results
                    ]
                    yield SSEEvent(
                        event="stage_complete",
                        data={
                            "stage": "refined_filter",
                            "message": f"ç²¾ç»†åŒ–ç­›é€‰å®Œæˆ,æœ€ç»ˆ {len(final_results)} ç¯‡æ–‡æ¡£",
                            "result": {
                                "document_ids": [
                                    doc.get("document_id") for doc in final_results
                                ],
                                "count": len(final_results),
                                "documents": result_summaries,
                            },
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

                elif node_name == "generate_answer":
                    # å‘é€ç”Ÿæˆç­”æ¡ˆçš„å¼€å§‹äº‹ä»¶
                    yield SSEEvent(
                        event="stage_start",
                        data={
                            "stage": "generate",
                            "message": "æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...",
                        },
                        id=task_id,
                        done=False,
                    ).model_dump_json()

            # è·å–æœ€ç»ˆçŠ¶æ€
            final_state = state_data if state_data is not None else {}

            # æ£€æŸ¥æ˜¯å¦æœ‰æ­§ä¹‰æ¶ˆæ¯éœ€è¦ç”¨æˆ·æ¾„æ¸…
            if final_state.get("ambiguity_message"):
                yield SSEEvent(
                    event="ambiguity",
                    data={"message": final_state["ambiguity_message"]},
                    id=task_id,
                    done=True,
                ).model_dump_json()
                return

            # å‘é€æ£€ç´¢åˆ°çš„æ–‡æ¡£å¼•ç”¨
            final_results = final_state.get("final_results", [])
            if final_results:
                references = []
                for i, doc in enumerate(final_results):
                    references.append(
                        {
                            "document_id": doc.get("document_id", i),
                            "title": doc.get("title", "æœªçŸ¥æ–‡æ¡£"),
                            "snippet": (
                                doc.get("content", "")[:200] + "..."
                                if doc.get("content")
                                else ""
                            ),
                            "score": 1.0,
                        }
                    )

                yield SSEEvent(
                    event="references",
                    data={"references": references},
                    id=task_id,
                    done=False,
                ).model_dump_json()

            # å‘é€æœ€ç»ˆç­”æ¡ˆ
            answer = final_state.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚")
            yield SSEEvent(
                event="answer",
                data={"content": answer},
                id=task_id,
                done=False,
            ).model_dump_json()

            await asyncio.sleep(0.5)

            # å‘é€å®Œæˆä¿¡å·
            yield SSEEvent(
                event="complete",
                data={"message": "å›ç­”å®Œæˆ"},
                id=task_id,
                done=True,
            ).model_dump_json()

        except Exception as e:
            traceback.print_exc()
            yield SSEEvent(
                event="error",
                data={"message": f"æ™ºèƒ½ä½“é—®ç­”å¤±è´¥: {str(e)}"},
                id=task_id,
                done=True,
            ).model_dump_json()
        finally:
            # å…³é—­Elasticsearchå®¢æˆ·ç«¯
            if es_client:
                await es_client.close()

    return EventSourceResponse(event_generator())


@router.post("/ask/agent/clarify")
async def clarify_question_agent(
    request: Request,
    qa_request: QARequest,
    clarification: str,
    session_id: str,
    db: AsyncSession = Depends(get_db),
    config: DynamicConfig = Depends(get_config),
    current_user: User = Depends(get_current_user),
):
    """
    æ¾„æ¸…é—®é¢˜åç»§ç»­æ™ºèƒ½ä½“é—®ç­”æµç¨‹

    - **question**: ç”¨æˆ·é—®é¢˜
    - **template_id**: é™å®šæ¨¡æ¿IDèŒƒå›´ï¼ˆå¿…éœ€ï¼‰
    - **clarification**: ç”¨æˆ·å¯¹æ­§ä¹‰é—®é¢˜çš„æ¾„æ¸…
    - **session_id**: ä¼šè¯ID

    è¿”å›æµå¼äº‹ä»¶ï¼š
    - **thinking**: æ€è€ƒè¿‡ç¨‹çŠ¶æ€æ›´æ–°
    - **references**: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å¼•ç”¨
    - **answer**: æµå¼ç”Ÿæˆçš„ç­”æ¡ˆç‰‡æ®µ
    - **complete**: å›ç­”å®Œæˆæ ‡è®°
    - **error**: é”™è¯¯ä¿¡æ¯
    """

    # æ£€æŸ¥template_idæ˜¯å¦æä¾›
    if not qa_request.template_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ä½¿ç”¨æ™ºèƒ½ä½“é—®ç­”å¿…é¡»æä¾›template_id",
        )

    async def event_generator():
        """SSEäº‹ä»¶ç”Ÿæˆå™¨"""
        es_client = None  # åˆå§‹åŒ–
        # ç”Ÿæˆä¼šè¯/ä»»åŠ¡IDï¼ˆæ•´ä¸ªæµç¨‹ä½¿ç”¨åŒä¸€ä¸ªUUIDï¼‰
        task_id = str(uuid.uuid4())
        try:
            # æ£€æŸ¥ä¼šè¯IDæ˜¯å¦å­˜åœ¨
            if session_id not in graph_state_storage:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="æ— æ•ˆçš„ä¼šè¯IDæˆ–ä¼šè¯å·²è¿‡æœŸ",
                )

            # è·å–å­˜å‚¨çš„çŠ¶æ€
            stored_state = graph_state_storage[session_id]

            # æ›´æ–°é—®é¢˜ä¸ºæ¾„æ¸…åçš„é—®é¢˜
            stored_state["query"] = f"{stored_state['query']} {clarification}"
            # æ¸…é™¤æ­§ä¹‰æ¶ˆæ¯
            stored_state["ambiguity_message"] = None

            # åˆå§‹åŒ–Elasticsearchå®¢æˆ·ç«¯
            es_client = AsyncElasticsearch(
                [config.ELASTICSEARCH_URL], verify_certs=False
            )
            stored_state["es_client"] = es_client

            # å‘é€å¼€å§‹å¤„ç†æ¶ˆæ¯
            yield SSEEvent(
                event="thinking",
                data={
                    "stage": "start",
                    "message": "æ­£åœ¨å¤„ç†æ‚¨çš„æ¾„æ¸…...",
                },
                id=task_id,
                done=False,
            ).model_dump_json()

            # ç»§ç»­è¿è¡ŒLangGraphæ™ºèƒ½ä½“å›¾
            # type: ignore
            final_state = await search_agent_app.ainvoke(
                dict(stored_state),
                config={
                    "configurable": {
                        "db": db,
                        "es": es_client,
                        "es_index": config.ELASTICSEARCH_INDEX,
                    }
                },
            )

            # å‘é€æ£€ç´¢åˆ°çš„æ–‡æ¡£å¼•ç”¨
            final_results = final_state.get("final_results", [])
            if final_results:
                references = []
                for i, doc in enumerate(final_results):
                    references.append(
                        {
                            "document_id": doc.get("document_id", i),
                            "title": doc.get("title", "æœªçŸ¥æ–‡æ¡£"),
                            "snippet": (
                                doc.get("content", "")[:200] + "..."
                                if doc.get("content")
                                else ""
                            ),
                            "score": 1.0,
                        }
                    )

                yield SSEEvent(
                    event="references",
                    data={"references": references},
                    id=task_id,
                    done=False,
                ).model_dump_json()

            # å‘é€æœ€ç»ˆç­”æ¡ˆ
            answer = final_state.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚")
            yield SSEEvent(
                event="answer",
                data={"content": answer},
                id=task_id,
                done=False,
            ).model_dump_json()

            # å‘é€å®Œæˆä¿¡å·
            yield SSEEvent(
                event="complete",
                data={"message": "å›ç­”å®Œæˆ"},
                id=task_id,
                done=True,
            ).model_dump_json()

            # æ¸…é™¤å­˜å‚¨çš„çŠ¶æ€
            if session_id in graph_state_storage:
                del graph_state_storage[session_id]

        except Exception as e:
            # å‘é€é”™è¯¯äº‹ä»¶
            yield SSEEvent(
                event="error",
                data={"message": f"æ™ºèƒ½ä½“é—®ç­”å¤±è´¥: {str(e)}"},
                id=task_id,
                done=True,
            ).model_dump_json()
        finally:
            # å…³é—­Elasticsearchå®¢æˆ·ç«¯
            if es_client:
                await es_client.close()

    return EventSourceResponse(event_generator())
